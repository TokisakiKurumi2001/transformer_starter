!include data.multi30k.de-en.yaml
!include transformer.base.yaml
!include translator.greedy.yaml

epochs: 20
batch_size: 64

optimizer:
  name: torch.optim.Adam
  lr: 0.0001
  betas: 
  - 0.9
  - 0.98
  eps: 1.0e-9

scheduler:
  name: Scheduler
  dim_embed: 512 # make sure this aligns with the model
  warmup_steps: 4000

loss:
  name: TranslationLoss
  label_smoothing: 0.1
