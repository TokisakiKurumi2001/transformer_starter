!include data.iwslt2017.de-en.yaml
!include transformer.base.yaml

epochs: 40
batch_size: 32

optimizer:
  name: torch.optim.Adam
  lr: 0.0001
  betas: 
  - 0.9
  - 0.98
  eps: 1.0e-9

scheduler:
  name: Scheduler
  dim_embed: 512 # make sure this aligns with the model
  warmup_steps: 4000

loss:
  name: TranslationLoss
  label_smoothing: 0.1
