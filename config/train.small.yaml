!include data.multi30k.de-en.yaml
!include transformer.base.yaml

epochs: 20
batch_size: 32

optimizer:
  name: torch.optim.Adam
  betas: 
  - 0.9
  - 0.98
  eps: 1.0e-9

scheduler:
  name: Scheduler
  dim_embed: 128 # make sure this aligns with the model
  warmup_steps: 10000

loss:
  name: TranslationLoss
  label_smoothing: 0.1

val_loss:
  name: TranslationLoss
  label_smoothing: 0.0
